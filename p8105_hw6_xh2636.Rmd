---
title: "p8105_hw6_xh2636"
author: "Xiaoyu Huang"
date: "2023-11-27"
output: github_document
---

```{r}
library(tidyverse)
library(ggplot2)
library(modelr)
library(mgcv)
library(dplyr)
library(readxl)
library(broom)
library(purrr)
```

# Problem 1
```{r,warning=FALSE}
# Load the raw data
path <- "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data <- read.csv(path)

# Adding the city state variable
homicide_data <- homicide_data %>%
  mutate(city_state = paste(city, state, sep = ", "))

# Adding the binary variable indicating whether the homicide is solved
homicide_data <- homicide_data %>%
  mutate(resolved = as.numeric(disposition == "Closed by arrest"))

homicide_data <- homicide_data %>%
  mutate(victim_age = as.numeric(victim_age))

# Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO; Tulsa, AL
homicide_data <- homicide_data %>%
  filter(!(city_state %in% c('Dallas, TX', 
                             'Phoenix, AZ', 'Kansas City, MO', 'Tulsa, AL')))

homicide_data <- homicide_data %>%
  filter(victim_race %in% c("White", "Black"))

view(homicide_data)
```

```{r,warning=FALSE}
# use the glm function to fit a logistic regression with resolved vs unresolved
baltimore <- filter(homicide_data, city == 'Baltimore' & state == 'MD')

model <- glm(resolved ~ victim_age + victim_race + victim_sex,
    data = baltimore,
    family = binomial()) 

# apply the broom::tidy to this object
model %>% 
  broom::tidy() %>%
  mutate(
    adjusted_OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, adjusted_OR, CI_lower, CI_upper) %>% 
  knitr::kable(digits = 3)
```

```{r}
# run glm for each of the cities in your dataset, and extract the adjusted odds ratio
city_model <- homicide_data %>% 
  nest(data = -city_state) %>%
  mutate(
    fit = map(.x = data, ~ glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
    output = map(fit, broom::tidy)
  ) %>%
  unnest(cols = output) %>%
  filter(term == "victim_sexMale") %>%
  mutate(adjusted_OR = exp(estimate),
         CI_lower = exp(estimate - 1.96 * std.error),
         CI_upper = exp(estimate + 1.96 * std.error)) %>%
  select(city_state, adjusted_OR, CI_lower, CI_upper) 

# Plot the graph
city_model %>%
  mutate(city_state = fct_reorder(city_state, adjusted_OR)) %>%
  ggplot(aes(x = city_state, y = adjusted_OR, ymin = CI_lower, ymax = CI_upper)) +
  geom_point() + 
  geom_errorbar() +
  coord_flip() +
  theme(legend.position = "none") +
  labs(
    title = "Adjusted Odds Ratios for by City",
    x = "City",
    y = "Adjusted Odds Ratio",
    caption = "Error bars represent 95% Confidence Intervals"
  )
```

# Problem 2
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())

view(weather_df)
```

```{r}
# Use 5000 bootstrap samples and produce estimates of these two quantities. 
set.seed(1)

bootstrap_result <- weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(
      models         = map(strap, ~lm(tmax ~ tmin, data = .x) )
    , results_tidy   = map(models, broom::tidy)
    , results_glance = map(models, broom::glance)
  ) %>% 
  select(-strap, -models)

view(bootstrap_result)
```

```{r}
# R2
r2_appro <-
  bootstrap_result %>%
  select(-results_tidy) %>%
  unnest(results_glance) %>%
  select(.id, r.squared)

# Plot the distribution of your estimates of R2
r2_appro %>%
  ggplot(aes(x = r.squared)) + geom_density() +
  labs(
    title = "Distribution of Estimates of Coefficient R2"
    , x = ""
    , y = "Density"
  )
```

```{r}
# 95% confidence interval for R2
quantiles_r2 <- quantile(r2_appro$r.squared, c(0.025, 0.975), na.rm = TRUE)
quantiles_r2
```
As we can see from the result, The 95% confidence interval around the estimate of R2 is given by [0.8861, 0.9383]. The graph shows like a normal distribution, but a appreance left skewed also.

```{r}
# Log
log_appro <-
  bootstrap_result %>%
  select(-results_glance) %>%
  unnest(results_tidy) %>%
  select(.id, term, estimate) %>%
  mutate(
    term = ifelse(term == "(Intercept)", "b1", ifelse(term == "tmin", "b2", term))
  ) %>%
  pivot_wider(
      names_from  = term
    , values_from = estimate
  ) %>%
 transmute(log_prod = log(b1 * b2))

# create a density plot of the distribution of our estimates
log_appro %>%
  ggplot(aes(x = log_prod)) + geom_density() +
  labs(
    title = "Distribution of Estimates of log(beta1 * beta2)"
    , x = ""
    , y = "Density"
  )
```

```{r}
# 95% confidence interval for R2
quantiles_log <- quantile(log_appro$log_prod, c(0.025, 0.975), na.rm = TRUE)
quantiles_log
```
As we can see from the result, The 95% confidence interval around the estimate of R2 is given by [2.049, 2.133]. The graph shows like a normal distribution, but a little left skewed. 

# Problem 3
```{r}
# Load and clean the data for regression analysis convert numeric to factor
brithweight <- read.csv("./data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(babysex = factor(babysex, levels = c(1, 2), 
                     labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", 
                              "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")))
```

```{r}
# Checcking for missing value
sum(is.na(brithweight))
```


